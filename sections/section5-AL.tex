\section{Active learning}\label{sec:AL}
The last section established the surrogate-based likelihoods $L_{D, \text{GPR}}$ and $L_{D, \text{LR}}$, given by Equation \eqref{eq:GPR-likelihood} and Equation~\eqref{eq:LR-likelihood}, respectively.
These two likelihoods are then used to compute the surrogate-informed posteriors $\pi_{P\mid D, Y^m = y^m} $ given by Equation~\eqref{eq:surr-posterior}.

From a practical perspective, this is the only accessible posterior: it is consequently crucial to make sure that it approximates the true posterior $\pi_{P\mid Y^m = y^m}$ as closely as possible.
The quality of the approximation of the posterior is directly related to the quality of the surrogate model, which in turn depends on the training data $D$.
Consequently, we now turn our attention to the problem of selecting the training data in an optimal way, in order to maximize the quality of the posterior approximation under computational budget constraints.

We adopt an Active Learning (AL) framework, aiming to select the most informative points to evaluate the forward model $y$; the forward model evaluations are inexact but thanks to the FE adaptivity the tolerance on the discretization error can be controlled, so we also aim at selecting the optimal tolerance level for each evaluation.
The adaptive selection of the tolerance level has been shown to be particularly effective in reducing the computational costs for GPR in an IP setting, both for MAP estimates~\cite{SemlerWeiser2023,SemlerWeiser2024} and for posterior sampling~\cite{VillaniUngerWeiser2024}.
The methodology of the latter works is expanded and adapted to the present setting, considering the LR surrogate model and different target functions, and incorporating a discretization error covariance estimate for GPR. 

\subsection{General methodology}\label{sec:AL-method}

In order to describe the strategy, we will need to introduce some new elements and notation. \medbreak 

We start by considering a local error indicator function 
\begin{equation} \label{eq:loc-err-ind}
    e_{D} : \Omega \to \mathbb R
\end{equation} 
which quantifies the uncertainty at a given point $p \in \Omega$ of the surrogate model $y_D$ with training data $D=\{(p_i, \tau_i, y_i)\}_{i=1}^n$.
The expected error estimate for data $D$ is then given by
\begin{equation} \label{eq:glob-err-ind}
    E(D) = \int_{\Omega} e_{D}(p) \, \pi_{ Y^m = y^m}(p) \, dp.
\end{equation}

Moreover, we consider to have a certain computational budget $W$ to spend on the evaluations of the forward model $y$ necessary to generate the training data $D$. \medbreak 

In a design of experiments (DoE) setting, the problem of selecting training data $D$ can be formulated to selecting a design $\mc D = \{ (p_i, \tau_i) \}_{i=1}^n$ of evaluation points and tolerances, whose evaluation through the numerical forward model then provides the training data $D(\mc D) = \{ (p_i, \tau_i, H(f_{\tau_i}(\cdot, p_i)) \}_{i=1}^n$. \newline
As the computational costs of the forward model evaluations depend on the tolerance level and not on the resulting value, we write $W(\mc D)$ for the computational cost for the creation of $D(\mc D)$. \newline
Finally, it useful to talk about refinements of a design: for two designs $\mc D$ and $\mc D'$, we say that $\mc D'$ refines $\mc D$, denoted by $\mc D' \leq \mc D$, if for every $(p, \tau) \in \mc D$ there exists $(p, \tau') \in \mc D'$ such that $\tau' \leq \tau$, i.e.  $\mc D'$ contains all the evaluation points of $\mc D$ with a smaller or equal tolerance.
For $\mc D' \leq \mc D$, we write 
\[ 
W(\mc D' \mid D(\mc D)) \coloneq W(\mc D') - W(\mc D)
\] for the computational cost of computing $D(\mc D')$ having already computed $D(\mc D)$. \medbreak

By using the expected error $E(D)$ as an evaluation metric and the computational budget $W$ as a constraint, we can formulate the following optimal DoE problem:
\begin{equation} \label{prob:doe}
    \min_{\mc D} E(D(\mc D)) \quad \text{subject to} \quad W(\mc D) \le W,
\end{equation}
This problem cannot be solved directly, as the evaluation of $E(D(\mc D))$ requires knowledge of training data $D$ which is not available before the design is fixed and the forward model evaluations are performed.
A variety of approaches to optimal DoE problems exist~\cite{HuanJagalurMarzouk2024} and in the present setting we resort to a greedy sequential approach. 
This approach is based on the idea of incrementally selecting new points and tolerances to update the design by considering the information gathered so far, evaluating the model each step. \newline
This is a compromise between static designs, which first select the points and then evaluate the model, and Bayesian sequential lookahead methods, which marginalize on the outcome of future experiments at each step; while the latter can be extremely effective, in our setting the design includes not only the evaluation points but also the tolerance levels, rendering the greedy approach the most suitable. \medbreak

The sequential approach considers a fractionating of the budget $\Delta W_1, \dots, \Delta W_J$ and produces a sequence of designs $\mc D_0,\dots, \mc D_J$, where $\mc D_j$ refines $\mc D_{j-1}$ for every $j \in \{1,\dots, J\}$.
The designs are obtained by solving the following sequence of DoE problems:
\begin{equation} \label{prob:incremental-doe}
    \min_{\mc D_{j} \le \mc D_{j-1}} E(D(\mc D_{j})) \quad \text{s.t.} 
    \quad W(\mc D_{j} \mid D(\mc D_{j-1}) ) \le \Delta W_j, \ \text{ for every } \ j=1,\dots,J.
\end{equation} 
Notice that at each step, Problem~\eqref{prob:incremental-doe} is not yet directly numerically solvable; in fact:
\begin{enumerate}[label=\textbf{\arabic*}]    
    \item $E(D(\mc D_{j}))$ involves the computation of an integral with respect to the unknown posterior $\pi_{Y^m = y^m}$;
    \item the problem is a mixed continuous-combinatorial optimization problem with possibly non convex objective and constraints;
    \item the computational cost associated with a design is not known before the simulations are performed.
\end{enumerate}
These issue are overcome separately in the following ways:
\begin{enumerate}[label=\textbf{\arabic*}]
    \item interleave sampling steps and training steps: sample from the approximated posterior $\pi_{D_{j-1}, Y^m = y^m}$ before step $j$, concatenating the new samples to the chain $\mc S_{j-1}$ and discarding old samples to obtain the current posterior representation $\mc S_j$;
    \item the choice of new evaluation points is separated from the optimization of evaluation accuracies, splitting the problem into two simpler subproblems;
    \item the asymptotical estimates described in Section~\ref{sec:AdaFE} are adopted to estimate the computational cost of a design, leading for $\mc D = \{ (p_i, \tau_i) \}_{i=1}^n$ to the estimate
    \begin{equation} \label{eq:comp-cost}
        W(\mc D) = \sum_{i=1}^n W_{\tau_i} = \sum_{i=1}^n \tau_i^{- \frac{l \cdot  s}{r}}.
    \end{equation}
\end{enumerate}

For point \textbf{2}, the selection of new candidate points at step $j$ is based on an acquisition function derived from the expected error $E(D)$
\begin{equation}\label{eq:acq-fun-gen}
    \mc A_j(p) = \int_{\Theta} \alpha_{\mc D_{j-1}}(p, p') \, \pi_{P \mid Y^m = y^m}(p') \, dp',
\end{equation}
where $\alpha_{\mc D_{j-1}}(p, p')$ quantifies the reduction of error in $p'$ when adding $p$ to the design $\mc D_{j-1}$. 
In the following sections, specific versions of $\alpha_{\mc D_{j-1}}$ for GPR and LR surrogates will be described. \newline
The optimization of the evaluation tolerances is performed by solving Problem~\ref{prob:incremental-doe} as a function of the accuracies.
Precisely, at step $j$ let $\mc D_{j-1} = \{ (p_i, \tau_i) \}_{i=1}^{n_{j-1}}$ and new candidates $\{ p_{n+i} \}_{i=1}^{s}$; the admissible tolerances for designs that refine $\mc D_{j-1}$ and add new points among the candidates are given by
\begin{equation*}
    \mc T_j =  \Big \{ (\tilde \tau _1, \dots, \tilde \tau _{n_{j-1}+s}) \in ( \R ^+ \cup \{ +\infty \} ) ^{n_{j-1}+s} \mid \tilde \tau_i  \leq \tau_ i \text{ for } i \leq n_{j-1}\Big \},
\end{equation*}
where for $\tau_i = +\infty$ the corresponding point $p_i$ is excluded from the design.
The tolerance problem at step $j$ is then given by
\begin{equation} \label{prob:tolerance-doe}
    \min_{\mc D_{j} \in \bb D_j} E(D(\mc D_{j})) \quad \text{s.t.} 
    \quad W(\mc D_{j} \mid D(\mc D_{j-1}) ) \le \Delta W_j, 
\end{equation} 
where \[
\bb D_j = \{ \mc D = \{ (p_i, \tau_i) \}_{i=1}^{n_{j-1}+s} \mid (\tau_1, \dots, \tau_{n_{j-1}+s}) \in \mc T_j \}.
\]
\newpage

The following pseudo-algorithm summarizes the adopted methodology. \medskip

\par\noindent\rule[1mm]{\textwidth}{0.4pt}
\phantomsection \makeatletter\def\@currentlabel{Algorithm 1}\makeatother\label{algo:AGP}
\large{\textbf{Algorithm 1.} } \normalsize
\par\noindent\rule[2mm]{\textwidth}{0.2pt}
\textbf{Require:} initial design $\mc D_0$, fractionating of the budget $\Delta W_1,\dots, \Delta W_J$.
\par\noindent\rule[2mm]{\textwidth}{0.2pt}
Initialize sample chain $\mc S_0 = \emptyset$. \newline
Iterative solution of the training problem.
For $j =1, \dots, J$ do: 
\begin{enumerate}
    \item \textbf{Sample the posterior.} \newline
    Decide: $d_j$, $h_j \in \bb N$. \newline
    Sample $d_j$ points from $\pi_{P \mid D(\mc D_{j-1}), Y^m = y^m}$. \newline
    Discard the $h_j$ oldest samples from $\mc S_{j-1}$. \newline
    Concatenate the new samples to the remaining old samples to obtain $\mc S_j$.

    \item \textbf{Select the candidates.} \newline 
    Decide: $s_j \in \bb N$. \newline
    For any $p\in \Theta$, approximate the acquisition function~\ref{eq:acq-fun-gen} by
    \begin{equation}\label{eq:acq-fun-disc}
        \bar{\mc A}_j(p) \coloneq \frac{1}{|\mc S_j|}\sum_{p' \in \mc S_j} \alpha_{\mc D_{j-1}}(p, p') .
    \end{equation}
    Select $s_j$  local maximizers of $\bar{\mc A}_j$.

    \item \textbf{Select the tolerances.} \newline
    Solve the discretization of Problem~\ref{prob:tolerance-doe}
    \begin{equation}\label{prob:discrete-tol}       
        \min_{\mc D_{j} \in \bb D_j} \frac{1}{|\mc S_j|} \sum_{p' \in \mc S_j} e_{D(\mc D_j)}(p')  \quad \text{s.t.} 
        \quad W(\mc D_{j} \mid D(\mc D_{j-1}) ) \le \Delta W_j, 
    \end{equation} to obtain the new experimental design $\mc D_j $. \newline
    If $\tau_i = +\infty$ for some $(p_i, \tau_i) \in \mc D_j $, discard $(p_i, \tau_i) $ from $\mc D_j $.

    \item \textbf{Evaluate the model.} \newline
    For every $(p_i, \tau_i )$ in $\mc D_j$: \begin{itemize}[nosep]
        \item if $(p_i, \tau_i ) \notin \mc D_{j-1}$, i.e. it's a new point or the tolerance was updated, set $y_i = H(f_{\tau_i}(\cdot, p_i))$ and include $(p_i, \tau_i, y_i)$ in $D(\mc D_j)$;
        \item else, there exists $(p_i, \tau_i, y_i) \in D(\mc D_{j-1})$: include it in $D(\mc D_j)$.
    \end{itemize}
    Train the surrogate model on $D(\mc D_j)$, obtain $y_{D(\mc D_j)}$.
\end{enumerate}
Decide: $d_{J+1}$, $h_{J+1} \in \bb N$. \newline
Sample $d_{J+1}$ points from $\pi_{P \mid D(\mc D_J), Y^m = y^m}$. \newline
Discard the $h_{J+1}$ oldest samples from $\mc S_J$. \newline
Concatenate the new samples to the remaining old samples to obtain $\mc S_{J+1}$. \newline
Return the resulting surrogate model $y_{D(\mc D_J)}$ and posterior samples $\mc S_{J+1}$.
\par\noindent\rule[3.5mm]{\textwidth}{0.4pt}

The algorithm depends on a number of parameters, namely the fractionating of the budget $\Delta W_j$, the numbers of samples to draw $d_j$ and to discard $h_j$, and the number of candidates to select $s_j$.
These parameter have to be decided by the user, and Section~\ref{sec:setup} will describe the choices made in this work as well as give general guidelines for the selection of these parameters. 

\subsection{Active learning for GPR}\label{sec:GPAL}

For GPR surrogate models, we consider the local error indicator function 
\begin{equation} \label{eq:loc-err-GP}
    e_{D, \text{GP}}(p) = \text{Trace} (k_D(p,p)),
\end{equation}
which can be interpreted as the expected value over the GP predictive posterior of the squared error of the surrogate model mean at $p$, as
\[
    \text{Trace} (k_D(p,p)) = \bb E_{y(p) \sim \mc N (m_D, k_D(p,p)) } \big[ \| m_{D}(p) - y(p)\|_2^2 \big].
\]
Note that, as the predictive covariance $k_D(p,p)$~\eqref{eq:predictive-var} does not depend on the model evaluations $y_i$, $e_{D, \text{GPR}}(p)$ can be computed when the design $\mc D$ is known, but the corresponding training set $D(\mc D)$ is not. 
This renders it possible to solve the tolerance problem~\eqref{prob:tolerance-doe} without any other approximation than the discretization of the integral as given in Equation~\eqref{prob:discrete-tol}.  \medbreak

As an acquisition function for new candidates we consider the sensitivity of the error indicator with respect to computational work spent in the point, following~\cite{SemlerWeiser2024,VillaniUngerWeiser2024}.\newline
Assume to be at step $j$ of the algorithm, with a design $\mc D_{j-1} = \{ (p_i, \tau_i) \}_{i=1}^{n_{j-1}}$.
We define the map 
\begin{gather*}
    \Gamma_{\mc D_{j-1}} : \Omega \times \Omega \times \R^+ \to SPSD_{\text{dim}\mc Y}(\R) \\
    (p', p, \tau) \mapsto k_{D(\mc D_{j-1} \cup \{(p, \tau)\}) }(p',p')
\end{gather*}
which maps a parameter point $p'$, a candidate point $p$ and a tolerance level $\tau$ to the predictive covariance of the surrogate model $y_{D(\mc D_{j-1} \cup \{(p, \tau)\}) }$ trained on any training data $D(\mc D_{j-1} \cup \{(p, \tau)\})$  resulting from the design $\mc D_{j-1}$ with the addition of the new point $(p, \tau)$.
Note that this map is well-defined as, for any design $\mc D$ and corresponding training data $D(\mc D)$, the predictive covariance $k_{D(\mc D)}$ is actually a function of $\mc D$ only and not of model evaluations, as noted above.\newline
Then, the sensitivity of the error indicator at $p'$ with respect to the computational work spent in $p$ for an evaluation at a given default tolerance $\tau_p$ is defined by
\begin{equation} \label{eq:alpha-GP}
    \alpha_{\mc D_{j-1}, \text{GP}}(p, p') = \frac{\partial \Gamma_{\mc D_{j-1}}}{\partial \tau} \bigg |_{(p',p,\tau_p)} \frac{\partial \tau}{\partial W}\bigg |_{W(\tau_p)},
\end{equation}
where $W(\tau)$ is the estimate given by (!!) for the computational work needed to evaluate the forward model with tolerance $\tau$ and $\tau(W)$ is the inverse of such relation. \newline
Note that the derivatives are well defined for every $\tau >0$ as long as the discretization noise covariance $\Sigma_D(\tau)$ is differentiable with respect to $\tau$, as in the case given by Equation~\eqref{eq:iid-GPR-noise}. 
For the explicit expressions of the derivatives with the current notation, we refer to the Appendix~\ref{app:derivatives}.

The acquisition function is then given by~\eqref{eq:acq-fun-gen} with $\alpha_{\mc D_{j-1},\text{GP}}$ as in~\eqref{eq:alpha-GP}. 
It depends on the default tolerance parameter $\tau_p$, which can be either a fixed value or a function of the point $p$; in~\cite{VillaniUngerWeiser2024} it is set to the average over the components of the predictive standard deviation, i.e.
\[ \tau_p = \frac{1}{\text{dim}\mc Y} \sum_{i=1}^{\text{dim}\mc Y} \sqrt{ \big (k_{D(\mc D_{j-1})}(p,p) \big )_{i,i}}. \]  \medbreak

In this work, we further attempt to improve the efficiency of GPR by inferring the noise covariance $\Sigma_D(\tau)$ from the evaluations of the forward model.
As the model evaluations are performed through Adaptive FE, for each data point $(p, \tau, y) \in D$ we will have a sequence of evaluations $y^{(1)}, \dots, y^{(m)}$ with decreasing tolerance levels $\tau^{(1)} > \dots > \tau^{(m)} = \tau$, corresponding to the sequence of FE refinements.
We aim at exploiting this evaluations to estimate the noise covariance $\Sigma_D(\tau)$ for the GPR model under certain assumptions by adopting a linear shrinkage estimator~\cite{LedoitWolf2019}.

\todo[inline]{describe covariance estimator}


\subsection{Active learning for LR}\label{sec:LRAL}
\todo[inline]{in this section I chose to introduce a general error indicator function for LR, and then to specialize it for the case of independent discretization noise components (similarly as done in Sections~\ref{sec:LR} and~\ref{sec:LRlike}), but the general error indicator function is not super meaningful so maybe can be omitted.}

For a LR surrogate model $y_{D,\text{LR}}$, let $\Sigma^2_{y_{D,\text{LR}}}(p)$ be the covariance matrix of the distribution $y_{D,\text{LR}}(p) = \mc U (\mc PI_p)$, where we recall that $\mc PI_p$ is the predictive interval given by Equation~\eqref{eq:LR-PI-general}.\newline
Then, the considered local error indicator function is the vector 1-norm of the square root $\Sigma_{y_{D,\text{LR}}}(p)$ of $\Sigma^2_{y_{D,\text{LR}}}(p)$,
\begin{equation} \label{eq:loc-err-LR-general}
    e_{D, \text{LR}}(p) = \left\| \text{vec}(\Sigma_{y_{D,\text{LR}}}(p)) \right\|_1.
\end{equation}
In the case of independent discretization noise components described by Proposition~\ref{prp:LR-const}, as the predictive interval given by Equation~\eqref{eq:LR-PI} is
\begin{equation*}
    \mc PI_p = \bigotimes_{j=1}^{\text{dim}\mc Y} \left[ LB^{(j)}(p), UB^{(j)}(p)\right],
\end{equation*}
we have that
\[
    \Sigma^2_{y_{D,\text{LR}}} = \frac{1}{12} \text{diag} \left( UB^{(1)}(p) - LB^{(1)}(p), \dots, UB^{(\text{dim}\mc Y)}(p) - LB^{(\text{dim}\mc Y)}(p) \right),
\] and the local error indicator function can be computed by 
\begin{equation} \label{eq:loc-err-LR}
    e_{D, \text{LR}}(p) = \frac{1}{2\sqrt{3}} \sum_{j=1}^{\text{dim}\mc Y} \left( UB^{(j)}(p) - LB^{(j)}(p) \right).
\end{equation}
Note that neither in the general case~\eqref{eq:loc-err-LR-general} nor in the independent noise case~\eqref{eq:loc-err-LR} the error indicator function can be computed without the knowledge of the training data $D$: this is a significant difference with respect to the GPR case and requires the approximation of the error indicator function in the tolerance problem~\eqref{prob:tolerance-doe}.\medbreak

As an acquisition function for new candidates, we consider the expected error reduction in over the predictive interval $\mc PI_{p}$ for a new point $p$. \newline
Let us be at step $j$ of the algorithm, with a design $\mc D_{j-1} = \{ (p_i, \tau_i) \}_{i=1}^{n_{j-1}}$.
For a point $p \in \Omega$, a tolerance $\tau_p\in \R^+$ and a value $y\in \mc Y$, we write $D(p,\tau_p, y) = D(\mc D_{j-1} ) \cup \{(p, \tau_p, y)\}$ for the training data obtained by adding the point $p$ at tolerance $\tau_p$ and value $y$ to the available training data $D(\mc D_{j-1})$. \newline
The expected error reduction in $p'$ when adding $p$ at tolerance $\tau_p$ to the design $\mc D_{j-1}$ is then given by the expected value over the model response $Y_p$ and the discretization noise $\nu$ of the difference between the current error indicator and the error indicator resulting from training set $D(p,\tau_p, y)$:
\begin{equation}\label{eq:alpha-LR-general}
    \alpha_{\mc D_{j-1}, \text{LR}}(p, p') = 
    \bb E _{ (Y_p, \nu) \sim \mc U( \mc PI_p \times  [-\tau_p, \tau_p] ^{ \text{dim} \mc Y } )} 
    \left[ 
        e_{D(\mc D_{j-1}), \text{LR}}(p')- e_{D(p,\tau_p, Y_p + \nu ), \text{LR}}(p')
    \right].
\end{equation}
Note that $\alpha_{\mc D_{j-1}, \text{LR}}$ is always non negative, as the predictive interval $\mc PI_{p'}$ can only shrink when adding a new point to the design and $e_{D, \text{LR}}(p)$ decreases as the size of $\mc PI_{p'}$ decreases. \medbreak

For the independent noise case, we can explicitly compute the expected value in~\eqref{eq:alpha-LR}, obtaining a closed-form expression for $\alpha_{\mc D_{j-1}, \text{LR}}$ given by the following proposition.
\begin{restatable}[Expected error reduction]{prp}{EER} \label{prp:EER}
    Let $p, p' \in \Omega$ and $\tau_p \in \R^+$, let $D = \{ (p_i, \tau_i, y_i) \}_{i=1}^n$ be a training set, and let the hypothesis of Proposition~\ref{prp:LR-PI} hold. \newline
    Let $L^{(1)}, \dots L^{(\text{dim} \mc Y)}$ be the Lipschitz constants used in the LR surrogate.
    Then, the expected error reduction in $p'$ is given by \begin{equation}\label{eq:alpha-LR}
        \alpha_{D, \text{LR}}(p, p') =  \frac{1}{2\sqrt{3}m_{\mc Y}(\mc P I_p)} \sum_{j=1}^{\text{dim}\mc Y} EUI(p,p')^{(j)} - ELI(p,p')^{(j)},
    \end{equation}
    where $m_{\mc Y}$ is the Lebesgue measure over $\mc Y$ and the expected upper improvement $EUI$ and expected lower improvement $ELI$ in the $j$-th component are given by
    \begin{equation*}
        \makebox[\textwidth][c]{$
        EUI(p,p')^{(j)}  = 
        \begin{cases}
            2\tau_p(c_1^j (UB^{(j)}(p) -LB^{(j)}(p)) + \dfrac{1}{2} (LB^{(j)}(p)^2 - UB^{(j)}(p)^2)) &
            \text{if } \ UB^{(j)}(p) \leq c_1^j - \tau_p  
            \\[3ex]

            \dfrac{1}{6}((c_1^j - LB^{(j)}(p) + \tau_p)^3 - (c_1^j - LB^{(j)}(p) - \tau_p)^3)&
            \begin{aligned}
                \text{if } & \ c_1^j + \tau_p < UB^{(j)}(p) \\
                &\text{ and } LB^{(j)}(p) \leq c_1^j - \tau_p
            \end{aligned}
            \\[4ex]

            \dfrac{1}{6}(c_1^j+\tau_p-LB^{(j)}(p))^3 &
            \begin{aligned}
                \text{if } & \ c_1^j + \tau_p < UB^{(j)}(p) \\
                &\text{ and } c_1^j - \tau_p < LB^{(j)}(p) \leq c_1^j + \tau_p
            \end{aligned}
            \\[4ex]

            \dfrac{1}{6}((c_1^j - LB^{(j)}(p) + \tau_p)^3 - (c_1^j - UB^{(j)}(p) + \tau_p)^3) &
            \begin{aligned}
                \text{if } & \ c_1^j - \tau_p < UB^{(j)}(p) \leq c_1^j + \tau_p \\
                &\text{ and } c_1^j - \tau_p < LB^{(j)}(p) \leq c_1^j + \tau_p
            \end{aligned}
            \\[4ex]

            \begin{aligned}
                2\tau_p(c_1^j (c_1^j - \tau_p -LB^{(j)}(p)) &+ \dfrac{1}{2} (LB^{(j)}(p)^2 - (c_1^j-\tau_p)^2)) -\\
                &- \dfrac{1}{6} ( (c_1^j -UB^{(j)}(p) + \tau_p)^3 -8\tau_p^3)
            \end{aligned}&
            \begin{aligned}
                \text{if } & \ UB^{(j)}(p) \leq c_1^j + \tau_p \\
                &\text{ and } LB^{(j)}(p) \leq c_1^j - \tau_p
            \end{aligned}
            \\[5ex]
            0 & 
            \text{if } \  c_1^j + \tau_p  < LB^{(j)}(p)
        \end{cases}$
        }
    \end{equation*}
    and 
    \todo[inline]{write actual ELI}
    \begin{equation*}
        \makebox[\textwidth][c]{$
        ELI(p,p')^{(j)}  = 
        \begin{cases}
            2\tau_p(c_1^j (UB^{(j)}(p) -LB^{(j)}(p)) + \dfrac{1}{2} (LB^{(j)}(p)^2 - UB^{(j)}(p)^2)) &
            \text{if } \ UB^{(j)}(p) \leq c_1^j - \tau_p  
            \\[3ex]

            \dfrac{1}{6}((c_1^j - LB^{(j)}(p) + \tau_p)^3 - (c_1^j - LB^{(j)}(p) - \tau_p)^3)&
            \begin{aligned}
                \text{if } & \ c_1^j + \tau_p < UB^{(j)}(p) \\
                &\text{ and } LB^{(j)}(p) \leq c_1^j - \tau_p
            \end{aligned}
            \\[4ex]

            \dfrac{1}{6}(c_1^j+\tau_p-LB^{(j)}(p))^3 &
            \begin{aligned}
                \text{if } & \ c_1^j + \tau_p < UB^{(j)}(p) \\
                &\text{ and } c_1^j - \tau_p < LB^{(j)}(p) \leq c_1^j + \tau_p
            \end{aligned}
            \\[4ex]

            \dfrac{1}{6}((c_1^j - LB^{(j)}(p) + \tau_p)^3 - (c_1^j - UB^{(j)}(p) + \tau_p)^3) &
            \begin{aligned}
                \text{if } & \ c_1^j - \tau_p < UB^{(j)}(p) \leq c_1^j + \tau_p \\
                &\text{ and } c_1^j - \tau_p < LB^{(j)}(p) \leq c_1^j + \tau_p
            \end{aligned}
            \\[4ex]

            \begin{aligned}
                2\tau_p(c_1^j (c_1^j - \tau_p -LB^{(j)}(p)) &+ \dfrac{1}{2} (LB^{(j)}(p)^2 - (c_1^j-\tau_p)^2)) -\\
                &- \dfrac{1}{6} ( (c_1^j -UB^{(j)}(p) + \tau_p)^3 -8\tau_p^3)
            \end{aligned}&
            \begin{aligned}
                \text{if } & \ UB^{(j)}(p) \leq c_1^j + \tau_p \\
                &\text{ and } LB^{(j)}(p) \leq c_1^j - \tau_p
            \end{aligned}
            \\[5ex]
            0 & 
            \text{if } \  c_1^j + \tau_p  < LB^{(j)}(p)
        \end{cases}$
        }
    \end{equation*}
    for $c_1^j = UB^{(j)}(p') - L^{(j)} \| p - p' \|_\Omega -\tau_p$ and $c_2^j = -LB^{(j)}(p') + L^{(j)} \| p - p' \|_\Omega +\tau_p$.
\end{restatable}
For the sake of brevity the proof of this result is given in the Appendix~\ref{app:EER}, as it involves the integration of a piecewise linear function and needs to distinguish between different cases. \medbreak

With the expected error reduction $\alpha_{D, \text{LR}}$ at hand, the acquisition function for new candidates is given by~\eqref{eq:acq-fun-gen}. 
Like for the GPR acquisition function, it depends on the default tolerance parameter $\tau_p$, which can be treated as in the GPR case. \medbreak

As mentioned with the introduction of the LR error indicator function $e_{D, \text{LR}}$ in~\eqref{eq:loc-err-LR}, this function unlike $e_{D, \text{GPR}}$ cannot be computed without the knowledge of the training data $D$.
Thus, in the tolerance problem~\eqref{prob:tolerance-doe} the local error indicator function is substituted by its expected value over the model response and the discretization noise, similarly as done for the acquisition function~\eqref{eq:alpha-LR-general}.

