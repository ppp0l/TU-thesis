\section{Numerical experiments}\label{sec:exp}

In this section, we present numerical experiments to demonstrate the performance of~\ref{algo:AL} under different conditions. 
Among the three presented experiment, the first two use an analytical solution of the underlying PDE, while the third one is based on actual FE simulations of a PDE.
The choice of analytical forward models allows to evaluate the actual error and compare convergence rates and reduces the time required by realizations of~\ref{algo:AL}. 
At the end of the section, we will use the setup and data from the experiments to evaluate the influence of the estimation of the discretization noise's covariance on the quality of the GPR surrogate and of the GPR-based solution of the IP.  \medskip 

The remainder of this section is organized as follows: in Section~\ref{sec:setup}, we describe the objectives of the experiments and general setup across them; Section~\ref{sec:implementation} provides implementation details; in Section~\ref{sec:3dexp}, we present an analytical example with 3D parameter space based on the Laplace equation; in Section~\ref{sec:6dexp}, we present an analytical example with 6D parameter space based on the diffusion equation; in Section~\ref{sec:FEexp}, we present a FE example based on elastomechanics with 2D parameter space; finally, in Section~\ref{sec:cov-est}, we elaborate data from the previous experiments to assess the impact of noise covariance estimation.

\subsection{Objectives and general setup}\label{sec:setup}

The experiments aim at testing the proposed strategy on low to moderate-dimensional parameter spaces.
The scope of these examples can be articulated in three senses:
\begin{enumerate}
    \item comparing the training strategy as compared to other strategies for the same surrogate model;
    \item comparing the performance of LR surrogates to the more established GPR surrogate models across different training strategies;
    \item comparing the effect on GPR of discretization noise estimation as given by Equation~\eqref{eq:shrinkage-estimator} in Section~\ref{sec:GPAL}.
\end{enumerate}
While the first and the last points can be evaluated more easily, the second point is more difficult to evaluate as it requires a fair comparison between the two kinds of surrogate models.
Consequentely for point 2, we will exploit the available ground-truth in the analytical examples, while for the FE example we will resort to a qualitative comparison.

Unlike the experiments in~\cite{VillaniArconesUngerWeiser2025}, where various setups for the budget fractionating and the FE cost depending on the fraction $\frac{l}{r}$ were considered, in this work we fix them and do not investigate their effect on the performance of the algorithm.
Previous works~\cite{SemlerWeiser2023,VillaniArconesUngerWeiser2025,VillaniUngerWeiser2024} have shown that the effect of an higher FE cost is to reduce the effectiveness of tolerance optimization, resulting in performances similar to those of a fixed tolerance strategy.

As a benchmark, we consider the non-adaptive space-filling approach given by Latin Hypercube Sampling (LHS)~\cite{McKayBeckmanConover1979}, the approach proposed in~\cite{Dinkel2024}, which also relies on interleaved sampling but selects the candidates randomly from the current posterior approximation, both using fixed tolerances.
Moreover, we also consider the fixed tolerance version of the proposed strategy, which is given by~\ref{algo:AL} without the tolerance optimization step. 
For the GPR surrogate, we name the strategy of~\ref{algo:AL} \texttt{AGP} for adaptive Gaussian process, the fixed tolerance version \texttt{posAdGP} for position-adaptive Gaussian process, the strategy proposed in~\cite{Dinkel2024} \texttt{randGP} and the LHS strategy \texttt{LHSGP}.
Similarly, we will refer to the LR surrogate strategy of~\ref{algo:AL} as \texttt{ALR}, the fixed tolerance version as \texttt{posAdLR}, the LR version of the strategy proposed in~\cite{Dinkel2024} as \texttt{randLR} and the LHS version as \texttt{LHSLR}. \medskip

In all experiments, the measured quantity is directly obtained from pointwise evaluations $f(\theta)$ of the equation's solution $f$, for $\theta$ in a set of sensors $\mc S$; consequently, the measurement operator $H$ is given by
\[
    H(f(\cdot; p)) = \left( f(\theta_j)\right)_{j=1,\ldots, \text{dim} \mc Y} \ \text{ for some ordering } \ \theta_1, \ldots, \theta_{|\mc S|} \ \text{ of the sensors } \ \mc S.
\]
In the analytical examples $f(p) \in \R$, while for the FE example $f(p)\in \R^3$: in the latter case, only one component of the displacement is assumed to be measured in each sensor. \medskip

For the analytical examples the analytical formula of a solution is available and no discretization is necessary.
This allows us to evaluate the forward model $y(p)$ with close to zero cost, rendering it possible to represent the ground-truth posterior and to perform repeated runs of the algorithm. 
On the downside, this requires us to simulate the discretization error; we do so by adding by adding pseudorandom noise $\nu$ with the appropriate distribution to forward model evaluations $y(p)$. \newline
When training GPR surrogates, we consider zero mean Gaussian noise $\nu \sim \mc N (0, \tau^2 \Sigma_T^2)$ when simulating $y_\tau(p)$, where \[
\big(\Sigma_T\big)_{ij} = \sigma\big( \|\theta_i - \theta_j\|_{\mc Y} \big) \ \text{ for } \ \theta_i, \theta_j \in \mc S
\]
with $\sigma$ the probability density function of the centered normal distribution $\mc N(0, \frac{1}{2})$.
Such a setup allows us to evaluate the effect of the discretization noise on the GPR surrogate model.\newline
When training LR surrogates, we consider uniform noise $\nu \sim \mc U([-\tau, \tau]^{\text{dim} \mc Y})$ so that $I_\tau$ is an interval and the assumptions of propositions~\ref{prp:LR-PI},~\ref{prp:LR-likelihood} and~\ref{prp:EER} are met. \newline
In order to compensate for the lack of discretization noise and to evaluate the sensitivity of the algorithms to randomness, we will perform and average repeated runs of the algorithm with the same budget but different random seeds.
Details about the number of runs will be given in the respective sections. \medskip

For  GPR, we consider a separable RBF kernel 
\[
    k_{(\mathbf{L}, \lambda)}(p, p') =  \exp ( - \norm{p - p'}^2_{\mathbf{L}} ) \ K_\lambda,
\]
as introduced by equations~\eqref{eq:separable-kernel} and~\eqref{eq:RBF-kernel}, with diagonal $\mathbf{L} = \text{diag}(\ell_1, \dots, \ell_{\text{dim} \Theta})$, $\lambda = (\mathbf{s}, \mathbf{C}) $ and
\[
K_\lambda = \text{diag}(\mathbf{s}) + \mathbf{CC}^T,
\] 
where $\mathbf{s} \in \R^{\text{dim} \mc Y}$ is a scaling vector and $\mathbf{C} \in \R^{\text{dim} \mc Y \times 2}$ is a rank 2 matrix which models the correlation among components. 
Moreover, to stabilize the hyperparameters we consider a Gamma prior $\mc G(2, 10)$ for the lengthscales $\ell_1, \dots, \ell_{\text{dim} \Theta}$ and impose a constraint $\ell_i > 10^{-1}$ for all $i$.
\medskip

To produce a MCMC representation of the posterior, we consider Ensemble Sampling as introduced in Section~\ref{sec:IP-sol} using at each step a move selected randomly among the stretch move~\eqref{eq:stretch-move}, the walk move~\eqref{eq:walk-move} and the DIME move from~\cite{Boehl}, with probabilities 0.25, 0.25, 0.5 respectively. 
When initializing the sampler, we randomly select an initial state through LHS and then we perform burn-in sampling, testing the convergence of the sampler through the Gelman-Rubin statistic $\hat R$ defined in Equation~\eqref{eq:hatR} every 100 iterations.
\medskip

In this work, we fix some parameters of~\ref{algo:AL} across different experiments, while others are set according to the specific problem.
Regarding sampling, the number $n_w$ of walkers in the ensemble is selected depending on the dimensionality of the problem; the posterior is not sampled at every iteration but every $N_{\text{sample}}$ iterations: at iteration $j$, the number of samples to be drawn $d_j$ and the number of samples to be burned $b_j$ at Step 1. are given by
\[
d_j = b_j = \begin{cases}
    250 \cdot n_w \cdot  & \text{ if } j \equiv 0 \mod N_{\text{sample}} \\
    0 & \text{ otherwise}
\end{cases}.
\]
By this, whenever we sample the posterior we rebuild a totally new chain $\mc S_j$. 
Moreover, after the required accuracy level is reached, we stop the algorithm and sample the posterior with a larger number of samples $d_{J_{\max} +1} = 500 \cdot n_w$, while burning the previous $b_{J_{\max} +1} = 250 \cdot n_w$ samples.\newline
We consider a single candidate point at each iteration, selecting the global maximum of the acquisition function~\eqref{eq:acq-fun-disc}, $s_j = 1$ at Step 2. of~\ref{algo:AL}; regarding the budget $\Delta W_j$ for the tolerance optimization problem at Step 3., we consider a default tolerance $\tau$ and assign the budget $\Delta W_j = \tau^{-\frac{l}{r}}$ to the optimization problem, where $l$ and $r$ are the FE cost parameters.
We consider non uniform budget fractionating, adapting the computational budget for Problem~\eqref{prob:incremental-doe} to the convergence status by halving the default tolerance if the target quantity does not reduce adequately in $N_\text{sample}$ iterations; we set the fraction $\frac{l}{r}$ to $1$ for the analytical examples and to $1.5$, corresponding to quadratic FE $r=2$ on a 3D mesh $l=3$, for the elastomechanics example.  \newline
Finally, the tolerance level \texttt{tol} is selected to be proportional to the measurement's covariance for the GPR surrogate and to the measurement's standard deviation for the LR surrogate, as the error estimates are related to the surrogate's covariance and standard deviation respectevely.\medskip

\subsection{Implementation details}\label{sec:implementation}
A Python implementation of~\ref{algo:AL}, available at (...) along with the results, has been developed to conduct the experiments on an Intel Core i7-9700T Ã— 8 CPU. \medskip

The Gaussian process surrogate model uses a GPyTorch~\cite{GPyTorchPaper} base model, set to work with double-precision floating-point numbers.
GPyTorch's Adam is employed to optimize the hyperparameters on the marginal likelihood~\eqref{eq:marginal-likelihood}. \medskip

The two optimization problems to determine new candidate points and evaluation tolerances are solved through the SciPy optimizer \texttt{scipy.optimize.minimize}. 
For the GPR acquisition function, the exact gradient is not available and local maxima of~\eqref{eq:acq-fun-disc} are found using the L-BFGS-B algorithm~\cite{ZhuBirdNocedal}. 
As derivative information is available for the LR acquisition function~\eqref{eq:alpha-LR} and for the target of the tolerance problem, we employ the Sequential Least Squares Quadratic Programming (SLSQP) algorithm to solve Problem~\eqref{prob:discrete-tol} and to find maximizers of~\eqref{eq:acq-fun-disc} for a LR model. 
For tolerance optimization, before applying the SLSQP algorithm a coordinate transformation is applied in order to linearize the work constraint. 
In all cases, we adopt a multi-start approach by selecting a number of initial points through a low-discrepancy sequence. \medskip

To sample the posterior, we utilize the \texttt{emcee}~\cite{emceePaper} implementation of Ensemble Sampling. The posterior plots are then realized using the \texttt{corner} package~\cite{corner}. \medskip

While the interface for the experiments is also realized in Python, the FE model is implemented in C++17 through the \texttt{Kaskade 7} Finite Element toolbox~\cite{GoetschelSchielaWeiser2021}.\medskip

The rest of the implementation has been developed by the author and relies in particular on the \texttt{numpy} package~\cite{numpy}, while the \texttt{matplotlib} package~\cite{matplotlib} has been employed for the generation of plots. 

\subsection{3D analytical example - Laplace equation}\label{sec:3dexp}

The first numerical experiment involves the distributional Laplace equation on $\R^3$
\[
 \Delta f = \delta_{x_0}
\] 
with a Dirac's delta source centered in some $x_0 \in \R^3$ and decaying to zero at infinity
\[
\lim_{\| x \| \to \infty} f(x; x_0) = 0.
\]
As a solution, we consider Green's function for the 3D Laplace equation
\[
f(x; x_0) =  \frac{1}{2 \|x-x_0\|_2},
\]
where a multiplicative constant has been added for numerical stability reasons. \medskip

To formulate an IP, $x_0$ is assumed to be an unknown parameter and we aim at identifying it by measurements of $f(x;x_0)$ in sensors $x \in \mc S$ for 
\[
    \mc S = \left\{
        \begin{pmatrix}
            \cos( i \frac{\pi}{3}) \sin( j \frac{\pi}{2}) \\
            \sin( i \frac{\pi}{3}) \sin( j \frac{\pi}{2}) \\ 
            \cos( j \frac{\pi}{2})
        \end{pmatrix} 
        \in \R^3 \ \Big| \ i \in \{0,1,2,3,4,5\}, \ j \in \{0,1,2,3\}
     \right\},
\]
resulting in 14 sensors on the unit sphere and consequently a 14-dimensional measurement space $\mc Y = \R^{14}$. \newline
The parameter space is assumed to be $\Omega = \left[-\frac{1}{2}, \frac{1}{2}\right]^3$ and a Normal prior $\mc N (0, \frac{1}{6}I_3)$ is considered.

We generate measurements by adding pseudorandom noise $N \sim \mc N (0, \sigma^2 I_{14})$, with $\sigma = 10^{-2}$ to the exact forward model evaluations $y(p)$ for some $p$. 
We consider 5 different measurements corresponding to 5 different $p$ randomly extracted from the prior distribution and, as the discretization error is simulated, we perform 5 runs of each training strategy with different random seeds for each measurement.
\medskip

For the GPR surrogate, we consider an halting threshold $\texttt{tol} = \sigma^2 \cdot \frac{\text{dim} \mc Y }{20} = 7\cdot 10^{-5}$, where the factor $\frac{\text{dim} \mc Y}{20}$ is chosen to be proportional to the number of output components of the surrogate model, as the error model sums the predictive variance over the output components, and divided by a factor 20 to impose the surrogate model's variance to be smaller than the measurement's variance.
For all configurations, we sample every $N_{\text{sample}} = 3$ iterations and we set the number of walkers to $n_w = 32$.
We begin with an initial design of $5$ points selected through LHS and with default tolerance $\tau_d = 3 \cdot 10^{-2}$, and we perform a maximum of $J_{\max} = 10 \cdot N_{\text{samples}}$ iterations; when assigning the budget $\Delta W_j = \tau ^{-\frac{l}{r}}$ to the optimization problem, we use the default value $\tau= \tau_d$ for the first $2\cdot N_{\text{samples}}$ iterations and then every $N_{\text{sample}}$ iterations we halve it if the expected error has not reduced by a factor 4 compared to the $N_{\text{sample}}$-th latest iteration, i.e. if $\frac{E(D(\mc D_j))}{E(D(\mc D_{j-N_{\text{sample}}}))} > \frac{1}{4}$.

This setup results in the expected error per spent budget curves represented by Picture~\todo{add plot} for the different training strategies.
We see that, while \texttt{LHSGP} struggles to reduce the expected error and has a slower convergence rate, the fixed-tolerance strategies \texttt{posAdGP} and \texttt{randGP} are able to perform on par with \texttt{AGP} until they hit a plateau around an error level of $3\cdot 10^{-4}$, while \texttt{AGP} is able to reach the threshold $\texttt{tol}$ before the maximum number of iterations.
Moreover we observe that in this case random selection of the candidates in \texttt{randGP} is as effective as the position-adaptive strategy \texttt{posAdGP}, resulting in a similar convergence velocity.
As shown in Table \todo{add table}, while before the plateau \texttt{AGP} and the position-adaptive strategies achieve a similar performance in terms of expected error per budget, \texttt{AGP} uses a smaller number of iterations and training points as it adaptively reduces the default tolerance $\tau_d$ and optimizes work distribution.
The plateau phase motivates us to test the behavior of the fixed-tolerance strategies with a lower tolerance $\tau_d = 10^{-3}$: in this case \texttt{posAdGP} and \texttt{randGP} are able to reach the target threshold $\texttt{tol}$ as shown in Picture \todo{add plot}, but they require a larger computational budget and a similar number of iterations as \texttt{AGP} with the lower default tolerance $\tau_d =  3\cdot 10^{-2}$ \todo{add table}.
Finally, we observe that on average a run \texttt{AGP} does not include the selected candidate in \todo{number} iterations, resulting in an average number of points in the design.\medskip

For the LR surrogate, we consider a halting threshold $\texttt{tol} = \sigma \cdot \frac{\text{dim} \mc Y }{1.5} = 0.09\bar 3$, proportional to the measurement's standard deviation as the error model is based on the standard deviation of the LR surrogate.
For LR, we sample every $N_{\text{sample}} = 4$ iterations and we set the number of walkers to $n_w = 32$.
The initial design consists of 5 points selected through LHS and with default tolerance $\tau_d = 0.03$, and we perform a maximum of $J_{\max} = 8 \cdot N_{\text{samples}}$ iterations; when assigning the budget $\Delta W_j = \tau ^{-\frac{l}{r}}$ to the tolerance optimization problem at Step 3,, we use the default value $\tau= \tau_d$ for the first $2\cdot N_{\text{samples}}$ iterations and then every $N_{\text{sample}}$ iterations we halve it if the expected error has not reduced by a factor 2 compared to the $N_{\text{sample}}$-th latest iteration, i.e. if $\frac{E(D(\mc D_j))}{E(D(\mc D_{j-N_{\text{sample}}}))} > \frac{1}{2}$.
The different choices regarding configuration parameters as compared to GPR are due to the higher prediction variance and lower sensitivity of the LR surrogate model to computational work. 

Picture \todo{add plot} shows the expected error per budget curves for the different training strategies. 
We observe that, as opposed to the GPR surrogate, the fixed-tolerance strategies \texttt{posAdLR} and \texttt{randLR} perform on par with \texttt{ALR} until they meet the maximum number of iterations, while \texttt{ALR} is able to reach the target threshold $\texttt{tol}$ before the maximum number of iterations thanks to the adaptive budget allocation.
It is worth noting that \texttt{LHSLR} performs significantly worse than the other strategies, barely reducing the expected error at all, while \texttt{posAdLR} performs slightly better than \texttt{randLR}. 
In this case, the fully adaptive strategy \texttt{ALR} almost always includes the new candidate in the design, resulting in an average number of training points of \todo{number} over the 25 runs of the algorithm.
This fact, as well as the effectiveness of fixed-tolerance strategies, suggests that for LR the number of points is a more relevant factor than in GPR. \medskip

We compare the performance of the GPR and LR surrogates utilizing the available ground truth.
Table \todo{add table} shows the average error on the MAP estimate, posterior mean and posterior variance of the different strategies and different surrogates.
\todo[inline]{add comment on other strategies}
We can notice that the LHS-based strategies \texttt{LHSGP} and \texttt{LHSLR} are the ones showing the most performance difference between the two surrogate kinds in both relative and absolute value. 
In this example, LR is unable to obtain a good approximation of the posterior through a globally-accurate surrogate, while GPR is able to reach a good approximation of the posterior even with a non-adaptive globally-accurate surrogate.
For the adaptive strategies instead, LR is able to reach a similar performance as GPR by having a locally-accurate representation of the forward model, despite a slightly higher computational cost.
Picture \todo{add plot} shows the samples gathered from the posteriors from \texttt{LHSGP} and \texttt{LHSLR} as well as the ground truth for one of the runs.

\subsection{6D analytical example - Diffusion equation}\label{sec:6dexp}

The second numerical experiment involves the diffusion equation on $\R^3$
\[
f_t = \Delta f
\]
with initial conditions given by two Dirac's delta of opposite sign centered in some $x_p$ and $x_n$:
\[
f (0,x; x_p, x_n) = \delta_{x_p}(x) - \delta_{x_n}(x).
\]
We consider the difference of fundamental solutions of the diffusion equation centered in $x_p$ and $x_n$ as a solution of the above problem
\begin{equation}\label{eq:diffusion-solution}
f(t,x; x_p, x_n) = (4 \pi t)^{-\frac{3}{2}} \left( \exp \left( - \frac{\norm{x-x_p}_2^2}{4t}\right)- \exp \left( - \frac{\norm{x-x_n}_2^2}{4t}\right) \right).
\end{equation}
We treat $x_p, x_n$ as unknown parameters and want to identify them by measuring $u(t,x;x_p, x_n)$ for $t,x \in \mc S$, where $\mc S$ is a set of times in $\R^+$ coupled with sensors in $\R^3$ given by
\[
\mc S  = \left\{ (t,x) \in \R^+ \times \R^3 \ \Big| \ t = 0.3, 0.5 \ \text{ and } \ x = \begin{pmatrix}
            \cos( i \frac{2\pi}{3}) \sin( j \frac{\pi}{4}) \\
            \sin( i \frac{2\pi}{3}) \sin( j \frac{\pi}{4}) \\ 
            \cos( j \frac{\pi}{4})
        \end{pmatrix} 
         \text{ for } i \in \{0,1,2\}, \ j \in \{0,1,2,3,4\}
        \right\}.         
\]
This results in 15 sensors at 2 different times, resulting in a 30-dimensional measurement space $\mc Y = \R^{30}$. \newline
As a parameter space, $\Omega = [-1,1]^6$ is considered and a Normal prior $\mc N (0, \frac{1}{4}I_6)$ is assumed.
Measurements are generated by exact forward model evaluations $y(p)$ for 4 different values of $p$ randomly extracted from the prior distribution, to which pseudorandom noise $N \sim \mc N (0, \sigma^2 I_{30})$, with $\sigma = 2 \cdot 10^{-2}$ is added.
For each of the 4 measurements, we perform 3 runs of each training strategy with different random seeds. \medskip

The configuration parameters for the GPR surrogate are similar to those of the previous example: we choose an halting threshold of $\texttt{tol} = \sigma^2 \cdot \frac{\text{dim} \mc Y }{20} = 6\cdot 10^{-4}$; sampling is performed every $N_{\text{sample}} = 4$ iterations, with an ensemble comprising of $n_w = 64$ walkers.
The initial design consists of 13 points selected through LHS with default tolerance $\tau_d = 3 \cdot 10^{-2}$; we perform a maximum of $J_{\max} = 10 \cdot N_{\text{samples}}$ iterations and at Step 3. of the algorithm we assign $\Delta W_j = \tau ^{-\frac{l}{r}}$ computational budget, using the default value $\tau= \tau_d$ for the first $2\cdot N_{\text{samples}}$ iterations and then again halving it every $N_{\text{sample}}$ iterations if the expected error has not reduced by a factor 4 compared to the $N_{\text{sample}}$-th latest iteration, i.e. if $\frac{E(D(\mc D_j))}{E(D(\mc D_{j-N_{\text{sample}}}))} > \frac{1}{4}$.

The convergence curves resulting from the different training strategies with the above configuration are shown in Picture \todo{add plot}.
In this example, we observe that, despite an overall higher error level, the relative performance of the different strategies is similar to the previous experiment; the position-adaptive strategies \texttt{posAdGP} and \texttt{randGP} stall at an error level of $5\cdot 10^{-3}$, while \texttt{AGP} is able to reach the target threshold $\texttt{tol}$ before the maximum number of iterations and \texttt{LHSGP} is unable to reduce the expected error significantly.
In contrast to the previous example, \texttt{AGP} is closer to the fixed-tolerance strategies \texttt{posAdGP} and \texttt{randGP} in terms of expected error per budget, but also spends considerably less budget than the previous experiment: both of these effects can be due to the higher likelihood standard deviation $\sigma$, here set to $2\cdot 10^{-2}$ in contrast to $10^{-2}$ in the previous example, which makes the need for higher-accuracy evaluations less pressing.
This can also be seen in the lower number of iterations where no new candidate is selected, as shown in Table \todo{add table}.
Another considerable difference is that \texttt{LHSGP} performs significantly worse than the other strategies, likely due to the higher dimensionality of the parameter space which makes evenly spaced sampling less effective.

For the LR we tried configuration parameters similar to the previous one: after setting the halting threshold to $\texttt{tol} = \sigma \cdot \frac{\text{dim} \mc Y }{1.5} = 0.6$, we sampled every $N_{\text{sample}} = 5 $ iterations and set the number of walkers to $n_w = 64$.
The initial design consists of 13 points selected through LHS with default tolerance $\tau_d = 0.03$; we perform a maximum of $J_{\max} = 8 \cdot N_{\text{samples}}$ iterations and at Step 3. of the algorithm we assign $\Delta W_j = \tau ^{-\frac{l}{r}}$ computational budget, using the default value $\tau= \tau_d$ for the first $2\cdot N_{\text{samples}}$ iterations and then again halving it every $N_{\text{sample}}$ iterations if the expected error has not reduced by a factor 2 compared to the $N_{\text{sample}}$-th latest iteration, i.e. if $\frac{E(D(\mc D_j))}{E(D(\mc D_{j-N_{\text{sample}}}))} > \frac{1}{2}$.
This setup resulted in a poor performance for all strategies, as shown in Picture \todo{add plot}, with \texttt{LHSLR} performing the worst but also the adaptive strategies \texttt{ALR}, \texttt{posAdLR} and \texttt{randLR} being unable to reduce the expected error significantly; in particular, \texttt{ALR} spends considerably more budget than the fixed-tolerance strategies, as it tries to adaptively reduce the default tolerance $\tau_d$ but the expected error does not reduce correspondingly.

To try to improve the performance, on one side we raised the ratio threshold for the adaptive default tolerance reduction for \texttt{ALR} to $2/3$ in order to avoid unnecessary spending; on the other, we tried to lower the default tolerance $\tau_d$ to $10^{-2}$ and to $10^{-3}$ and consider more iterations in order to improve the results of all strategies.
While raising the threshold for \texttt{ALR} managed to curb the spending, the second measure did not significantly improve the overall performance of the considered strategies, as shown in Pictures \todo{add plot}.

The failure of LR on this problem can be attributed to the nature of the forward model; in fact, due to the rapid decay of the considered solution~\eqref{eq:diffusion-solution}, every component is flat on most of the parameter space besides a small region where $y$ is rather steep.
This kind of behavior is extremely difficult to capture with a LR surrogate, which considers a global Lipschitz constant for the forward model: for every sensor, the Lipschitz constant at fixed time is given by \todo{numbers, compute} for $t=0.3$ and by \todo{number} $t=0.5$, but for $x_p$ and $x_n$ outside of the ball \todo{compute ball}, then the Lipschitz constant goes down to \todo{number} for $t=0.3$ and \todo{number} for $t=0.5$.
Due to this behavior, the LR surrogate requires a great number of points in order to be able to reduce the uncertainty of its prediction in the flat region.

The comparison of the performance of the GPR and LR surrogates is shown in Table \todo{add table}, where we can see that the performance of GPR is considerably better than that of LR as also depicted in Picture \todo{add plot}, where we show the samples gathered from the posteriors from \texttt{AGP} and \texttt{ALR} as well as the ground truth for one of the runs.

\subsection{2D Finite Element example - Elastomechanics}\label{sec:FEexp}



\subsection{Effects of the discretization noise covariance's estimation}\label{sec:cov-est}



