\section{Preliminaries} \label{sec:preliminaries}

In the remainder of this section Section~\ref{sec:BIP} first introduces the basic concepts of Inverse Problems and then presents the Bayesian approach to IP, providing a general framework for the formulation of Bayesian Inverse Problems (BIPs) and the derivation of the posterior distribution of the unknown given the observations; Section~\ref{sec:IP-sol} presents some key techniques for the solution of IPs and their numerical treatment, with a focus on the Bayesian approach; Section~\ref{sec:PDE} introduces the basic concepts of Partial Differential Equation (PDE) models, with a focus on the Laplace equation, the diffusion equation and elastomechanic equations as they are the PDEs used in the numerical experiments of Section~\ref{sec:exp}; finally, Section~\ref{sec:AdaFE} presents the Finite Element (FE) method and its adaptive version, which is the solution method for PDEs considered throughout this work.

\subsection{Bayesian Inverse Problems}\label{sec:BIP}

The main reference for this section and the following is Tim Sullivan's Introduction to Uncertainty Quantification~\cite{Sullivan2015}, and other sources will be quoted when utilized. \medskip

Inverse Problems (IP) deal with the identification of some unknown parameter or function in a model through observations of the portion of reality that the model is intended to represent.\newline
Given a measurement $y^m$ in the measurement space $\mc Y$, also known as observation space, the goal of an IP is to identify the pre-image $p*$ in the parameter space $\Theta$ under a map \[y : \Theta \longrightarrow \mc Y \] known as the forward model or parameter-to-observation map.
If a unique $p*$ in $\Theta$ such that
\begin{equation}\label{eq:IP0}
    y(p*) = y^m
\end{equation}
exists, the IP admits a unique solution: but this case is an exception rather than a rule, especially when the observation $y^m$ is corrupted by noise.

A number of techniques have been developed to address from an analytical perspective the numerous issues which arise in an IP.
First, the problem can be reformulated as a least squares problem: for some norm $\| \cdot \| _\mc Y$ on $\mc Y$, Problem~\ref{eq:IP0} is generalized to a minimization problem
\begin{equation}\label{eq:IP1}
    \min_{p\in \Theta} \| y(p) - y^m \|_\mc Y.
\end{equation}
Under regularity conditions such as $\Theta$ and $\mc Y$ being Banach spaces and $y$ being a continuous map, this formulation cannot yet guarantee neither existence, nor unicity, nor stability of a solution $p*$ for every $y^m \in \mc Y$. Nonetheless, Problem~\ref{eq:IP1} is more general as it allows for solutions even if $y^{-1}(\{y^m\} )= \emptyset$, and on the practical side suggests the adoption of optimization techniques to solve IPs.

A second and often compatible approach is that of regularization techniques. 
This involves introducing additional information or constraints to stabilize the solution and make the problem well-posed. Regularization can be performed by the substitution of $y$ with some more treatable operator, or in the case of Variational Regularization by the formulation of a different minimization problem. 
Often, a regularization approach can be understood both from an operator approximation and a variational point of view: this applies to Tychonoff regularization, which can be seen as the addition of a stabilizing term to Problem~\ref{eq:IP1}
\begin{equation}\label{eq:Tycho}
    \min_{p\in \Theta} \big\| y(p) - y^m \big\|_\mc Y^2 + \lambda\big\| p - p^0 \big\|_\Theta^2,
\end{equation}
for some norm $\|\cdot\|_\Theta$ on $\Theta$, $p^0$ in $\Theta$ and $\lambda $ in $ \R^+$. \medskip

As we will see in the next section, both these techniques can be understood by adopting a statistical perspective to IPs, which considers observations corrupted by noise with random behavior and known distribution.
A parameter-to-observation relation is assumed, rendering the available observation $y^m$ a realization of a random variable $Y^m$ over the measurement space $\mc Y$.
We consider an additive noise model
\begin{equation}\label{eq:par-to-obs}
    Y^m = y(p) + N,
\end{equation}
for noise $N$ with distribution $\bb P _N$. \newline
Equation~\eqref{eq:par-to-obs} deals that for any $p$ in $\Theta$, the distribution of $Y^m$ given $p$, noted $\bb P_{Y^m \mid p}$, is given by 
\[
    \bb P_{Y^m \mid p} (A) = \bb P_N (A-y(p))
\]
for any Borel set $A$ in $\mc B (\mc Y)$. 
Note that as $p$ is not a random variable, the distribution $\bb P_{Y^m \mid p}$ is not a conditional distribution and in this context the notation is meant to highlight the dependence of the distribution on the parameter $p$. \newline
For $\mc Y$ of finite dimension, the above equation can be expressed in terms of the probability density functions of $N$ and $Y^m$ with respect to the Lebesgue measure $m_\mc Y$.
As a function of the parameter $p$, the density of $Y^m$ given $p$ is called likelihood and given by
\begin{equation}\label{eq:likelihood}
    L(p) = \pi_{Y^m \mid p} (y^m) = \pi_N(y^m - y(p)).
\end{equation}
The likelihood of a problem is a crucial element in statistical IPs. \medskip

A natural development of the statistical approach to Inverse Problems are Bayesian Inverse Problems (BIPs). 
In the Bayesian setting, the unknown solution $p*$ of the IP is treated as a random variable $P$ and the solution of the IP then becomes the conditional distribution $\bb P_{P \mid Y^m=y^m} $ of $P$ given $Y^m=y^m$.

In full generality, the following result guarantees the possibility of formulating BIPs for arbitrary dimensionality:
\begin{thm} [Regular conditional probability]
    Let $ (\Omega, \mc F , \bb P) $ be a probability space, $\Theta$ be a separable Banach space equipped with the Borel $\sigma$-algebra $\mc B (\Theta)$, $(\mc Y, \tilde{\mc F})$ be a measurable space.
    Further, let $Y^m:\Omega \rightarrow \mc Y$ and $P : \Omega \rightarrow \Theta$ be random variables with $P \in L^1(\Omega, \bb P; \Theta) $. \newline
    Then there exists a $\bb P_{Y^m}$-a.s. unique map $\bb P_{P \mid Y^m} : \mc B (\Theta) \times \mc Y \rightarrow [0,1] $ such that :
    \begin{itemize}
        \item $\bb P_{P \mid Y^m}(\cdot, y)$ is a probability density on $\Theta$ for all $y$ in $\mc Y$;
        \item $\bb P_{P \mid Y^m}(A, \cdot)$ is measurable for all $A$ in $\mc B (\Theta)$;
        \item for all $B$ in $\sigma(Y^m)$, $A$ in $\mc B (\Theta)$, it holds that
                \[ 
                \int_B \bb P_{P \mid Y^m}(A, Y^m(\omega)) \ d\bb P(\omega)= \int_B \ind_A(P(\omega)) \ d\bb P(\omega).
                \] 
    \end{itemize}
    Such map is known as the regular conditional probability of $P$ given $Y^m$ and any map satisfying the first two properties is called a Markov kernel.
\end{thm}

This results guarantees the well-definiteness of conditional probabilities in a general setting, thus allowing for the formulation of BIPs in arbitrary dimensionality, but does not provide a direct way to formulate the posterior distribution given a parameter-to-observation relation. 
This is provided by Bayes' rule, which in generality is given by the following result from~\cite[Theorem 14]{DashtiStuart2017}:

\begin{thm}[Bayes' rule]
    Let $ (\Omega, \mc F , \bb P) $ be a probability space and $\Theta, \mc Y$ be separable Banach spaces equipped with the respective Borel $\sigma$-algebras. 
    Moreover, let $P : \Omega \rightarrow \Theta$ and $N:\Omega \rightarrow \mc Y$ be independent random variables, and $ Y^m = y(P) + N$ with $y: \Theta \rightarrow \mc Y$ a measurable map. \newline
    Assume $\bb P_{Y^m\mid P}(\cdot, p) \ll P_N$ for every $p \in \Theta$, that $\frac{d \bb P_{Y^m\mid P}(\cdot, p)}{d\bb P_N}(y) $ is $\bb P_{(P,N)}$-measurable, and that 
    \[
        \int_\Theta \frac{d \bb P_{Y^m\mid P}(\cdot, p)}{d\bb P_N}(y) \ d\bb P_P(p) > 0 \ \text{ for }  \ y, \ \bb P_N \text{-a.s.}
    \]
    holds.
    Then, the regular conditional probability $\bb P_{P\mid Y^m}(\cdot,y)$ for $P$ given $Y^m$ exists and is such that $\bb P_{P\mid Y^m}(\cdot, y) \ll \bb P _P$ $\bb P_{Y^m}$-a.s., with Radon-Nikodym derivative
    \begin{equation}\label{eq:infdimBayes}
        \frac{d\bb P_{P\mid Y^m}(\cdot, y)}{d\bb P_P}(p) = \frac{1}{Z(y)}\frac{d\bb P_{Y^m\mid P}(\cdot, p)}{d\bb P_{N}}(y).
    \end{equation}
\end{thm}

In the above theorem, $\bb P_P$ is the prior distribution of $P$ and $\bb P_{P \mid Y^m}(\cdot, y^m)$ is then the Bayesian posterior distribution of $P$ given $Y^m=y^m$.
As in~\cite[Theorem 6.31]{Stuart2010}, under certain hypothesis over the measurement space $\mc Y$, the distribution of the noise $\bb P_N$ and the forward model $y$, one has that the conditions over $\frac{d \bb P_{Y^m\mid P}(\cdot, p)}{d\bb P_N}(y)$ hold, rendering the application of the Theorem possible. \medskip

As for the scope of this work it is not necessary to work in full generality, now and for the rest of this work on it will be assumed that the involved spaces $\Theta, \  \mc Y$ are finite dimensional Banach spaces, and that $P$ and $Y$ are random vectors that admit a joint probability density function $\pi_{P,Y}$ with respect to the Lebesgue product measure $m_\Theta \otimes m_\mc Y$. 
This allows for a more intuitive and direct formulation of the Bayesian posterior distribution of $P$ given $Y=y^m$ by exploiting the conditional probability density.

\begin{thm}[Bayes' rule with Lebesgue measure]
    Let $Y = y(P) + N$ hold, with $P$ and $N$ independent and $y: \Theta \rightarrow \mc Y$ a measurable map.
    Then the conditional density of $Y^m$ given $P$ coincides with the likelihood~\eqref{eq:likelihood}, \[
        \pi_{Y^m\mid P = p}(y^m) = \pi_{N}(y^m - y( p) ) = L(p),
    \] and the posterior distribution of $P$ given $Y^m=y^m$ is given by the probability density \begin{equation}\label{eq:Bayes}
        \pi_{P\mid Y^m = y^m}(p) = \frac{\pi_{N}(y^m - y( p) ) \pi_P(p)}{\pi_{Y^m}(y^m)},
    \end{equation}
    where $\pi_{Y^m}(y^m)$ is the marginal density of $Y^m$ given by
    \[
        \pi_{Y^m}(y^m) = \int_\Theta  \pi_{N}(y^m - y( p) ) \pi_P(p) \ dm_\Theta(p).
    \]
\end{thm}

\subsection{Solutions of Inverse Problems}\label{sec:IP-sol}

What it means to solve an IP depends on its formulation and on the objectives that the solution serves.   
The least-squares formulation~\eqref{eq:IP1}, the regularization approach~\eqref{eq:Tycho} and non-Bayesian statistical IPs usually rely on point estimates; the Bayesian formulation instead can also provide a posterior distribution of the unknown given the observations. \medskip

In a statistical framework, the likelihood~\eqref{eq:likelihood} can be utilized to obtain a point estimate of the unknown $p*$ by Maximum Likelihood (ML) estimation
\begin{equation}\label{eq:ML}
    p^* = \arg \max_{p \in \Theta} L(p),
\end{equation}
which maximizes the likelihood of the observations $y^m$ given the parameter $p$.
As the likelihood often decays rapidly it is common to minimize the negative log-likelihood instead, solving the mathematically equivalent but numerically more stable problem \[
    p^* = \arg \min_{p \in \Theta} -\log L(p).
\]
For normal centered noise $N \sim \mc N(0, \Sigma^2)$, the negative log-likelihood is given by
\[
    -\log L(p) = \frac{1}{2} \| y^m - y(p) \|_{\Sigma^{-2}}^2 + \text{const}
\]
where $\| \cdot \|_{\Sigma^{-2}}$ is the norm induced by the inverse of the covariance matrix $\Sigma^2$ of the noise $N$ and $\text{const}$ is a constant term independent of $p$. 
By inserting the above expression in the minimization problem, we see that the ML estimate is equivalent to the minimization of the least-squares problem~\eqref{eq:IP1} with the choice of the norm $\| \cdot \|_{\Sigma^{-2}}$ on $\mc Y$.
By this, the statistical approach naturally provides both a justification and an interpretation for least-squares in IPs; the same happens to regularization techniques, but to see that we need to consider the Bayesian approach. \newline
Within the Bayesian framework, a point estimate can be obtained by Maximum A Posteriori (MAP) estimation which maximizes the posterior density~\eqref{eq:Bayes} of the unknown $P$ given the observations $Y^m=y^m$
\[
    p^* = \arg \max_{p \in \Theta} \pi_{P\mid Y^m = y^m}(p) = \arg \max_{p \in \Theta} L(p) \pi_P(p),
\]
where in the second equality we omitted the denominator $\pi_{Y^m}(y^m)$ as it is independent of $p$.
For normal centered noise $N \sim \mc N(0, \Sigma^2)$ and normal prior $P \sim \mc N(p_0, \Sigma_p^2)$, if we take the negative logarithm of $\pi_{P\mid Y^m = y^m}(p)$ and omit the constants, we can rewrite the MAP problem as
\[
    p^* = \arg \min_{p \in \Theta} \|y^m - y(p) \|_{\Sigma^{-2}}^2 + \|p - p_0 \|_{\Sigma_p^{-2}}^2.
\] 
This, for $\|\cdot \|_\mc Y = \|\cdot \|_{\Sigma^{-2}}$ and $\|\cdot \|_\Theta = \|\cdot \|_{ \lambda \Sigma_p^{-2}}$ is exactly the Least-Squares problem with Tychonoff regularization~\eqref{eq:Tycho}, allowing us to interpret the regularization term as an expression of prior beliefs over the parameter $p$ and the parameter $\lambda$ as a measure of confidence in the prior.
\medskip


While the point estimates can be significantly cheaper to compute, they do not provide a full characterization of the uncertainty in the solution by themselves.
To obtain a representation of the posterior distribution~\eqref{eq:Bayes} of the parameter $P$ given the observations $Y^m=y^m$, we consider Markov Chain Monte Carlo (MCMC) sampling.
MCMC techniques usually require a greater number of evaluations of the likelihood function and consequently of the forward model, but then provide a set of correlated samples from $\pi_{P\mid Y^m = y^m}$. 
Such a set of samples is particularly useful as it allows for Monte Carlo integration
\begin{equation}\label{eq:MC-integration}
    \bb E _{X \sim \bb P_X} [f(X)] = \int_\mc X f(x) \pi_X(x) \ dx \approx \frac{1}{N} \sum_{i=1}^{N} f(x_i).
\end{equation}
Under certain hypothesis on the generation of the samples $\{x_i\}_{i=1}^N$ from $\bb P_X$, a corresponding version of the Law of Large Numbers can guarantee convergence of the right-hand side to the left-hand side for $N \rightarrow \infty$ for any measurable function $f$ integrable with respect to $\bb P_X$.
For $X = P \mid Y^m = y^m$, Monte Carlo integration allows for the computation of several quantities of interest, such as for example the posterior mean and variance.

The first MCMC technique to be introduced was the Metropolis-Hastings (MH) algorithm, first introduced by~\cite{MetropolisRosenbluthRosenbluthTellerTeller1953} and later generalized by~\cite{Hastings1970}.
As MH includes key concepts that are also present in other MCMC techniques while being fairly simple, we will briefly introduce it here.
MH consists of the following algorithm:

\par\noindent\rule[1mm]{\textwidth}{0.4pt}
\phantomsection \makeatletter\def\@currentlabel{Algorithm }\makeatother\label{algo:MH}
\large{\textbf{Algorithm 1 - Metropolis-Hastings.} } \normalsize
\par\noindent\rule[2mm]{\textwidth}{0.2pt}
\textbf{Require:} $\bb P$ target distribution with density $\pi(p)$, a Markov kernel $\mc K$ with density $q(p \mid p ' )$, initial state $p_0$, $N$ samples to draw.
\par\noindent\rule[2mm]{\textwidth}{0.2pt}
For $i =1, \dots, N$ do: 
\begin{enumerate}
    \item Draw proposal $p_n$ from $\mc K (\cdot, p_{n-1})$
    \item Set acceptance threshold: \[ \alpha = \frac{\pi(p_n) q(p_{n-1} \mid p_n )}{\pi(p_{n-1}) q(p_n \mid p_{n-1} )} \]
    \item Draw $u$ from $\mathcal{U}([0,1])$
    \item If $u > \alpha$ then reject: $p_n \leftarrow p_{n-1}$
\end{enumerate}
\textbf{Return} $p_1, \dots, p_N$.
\par\noindent\rule[3.5mm]{\textwidth}{0.4pt}

We observe that, as the target distribution's density is utilized to compute the acceptance threshold $\alpha$ only through a ratio, it needs to be known up to a normalizing constant: this is crucial for the application in BIPs, where the normalizing constant is given by the marginal density $\pi_{Y^m}(y^m)$ which is usually unknown and whose estimation is usually challenging.
This property is fortunately shared by all MCMC techniques \newline
Similarly to Importance Sampling, MH relies on a proposal distribution $\mc K(\cdot, p)$ to generate samples; the rejection step then guarantees that the target distribution is invariant with respect to the sample chain $\{p_i\}$.
The proposal kernel $\mc K$ is crucial both for guaranteeing the convergence of the chain to the target distribution and for the efficiency of the sampling process. 
A sufficient condition for convergence is the absolute continuity of the proposal with respect to the target, i.e. $\mc K(\cdot, p) \ll \bb P $ for every $p$; however, a proposal tailored to the target will result in a better acceptance rate for new samples and both the convergence velocity and the quality of the samples will be higher. 

A number of techniques has been developed to address the issues related to the quality of the sampling process.
First, instead of fixing the proposal distribution, one can choose a family of kernels $\mc K_\theta$ and then adjust the parameter $\theta$ during the sampling process: for random walk MH, the optimal acceptance ratio balancing the exploration of the parameter space and the acceptance of new samples is around $0.234$~\cite{GelmanGilksRoberts1997}, and the proposal distribution can be tuned to achieve this value.
Second, a burn-in or warm-up period can be introduced in order to avoid transient behavior by allowing the chain to converge to the target distribution before starting to collect samples; this reduces the dependence of the resulting chain on the initial state and can improve the quality of the resulting chain.
Third, convergence diagnostics can be performed to assess the state of the chain's convergence to the target distribution and the mixing of the samples.
A commonly employed diagnostic is the Gelman-Rubin potential scale reduction $\hat R$ introduced by~\cite{GelmanRubin1992}, which utilizes multiple independent chains by computing the variance within each chain and the variance between all chains.
For $i =1, \dots, M$, let $\{ \theta_{j}^i \}_{j=1}^{N} \subseteq \R $ be independent chains of length $N$ and let the mean of each chain and overall mean be 
\[
    \bar \theta^i = \frac{1}{N} \sum_{j=1}^{N} \theta_{j}^i, \quad \text{and} \quad \bar \theta = \frac{1}{M} \sum_{i=1}^{M} \bar \theta^ii.
\]
Then, the between chain variance is given by
\[
    B = \frac{N}{M-1} \sum_{i=1}^{M} (\bar \theta^i - \bar \theta)^2,
\]
while the within chain variance is given by
\[
    W = \frac{1}{M} \sum_{i=1}^{M} \frac{1}{N-1} \sum_{j=1}^{N} (\theta_{j}^i - \bar \theta^ii)^2.
\]
An unbiased estimator of the variance of the target distribution is then given by
\[
    \hat \sigma^2 = \frac{N-1}{N} W + \frac{1}{N}B,
\]
and the potential scale reduction is defined as 
\begin{equation}\label{eq:hatR}
    \hat R = \sqrt{ \frac{\hat \sigma^2}{W} }.
\end{equation}
$\hat R$ quantifies the difference in variance between the different chains and is expected to converge to $1$ from above as the chains converge to the stationary distribution. 
Two common practices, both recommended by~\cite[Chapter 11.4]{GelmanCarlinSternDunsonVehtariRubin2013}, are to consider $\hat R < 1.1$ as a convergence criterion and to split each chain into two halves before computing the potential scale reduction in order to test for adequate mixing of each chain.
For multivariate distributions while generalizations of the potential scale reduction $\hat R$ exist, such as the one proposed by~\cite{BrooksGelman1998}, in practice it is common to consider the potential scale reduction of each component of the parameter vector separately and then to take the maximum value of the potential scale reduction across all components.

Once convergence to the stationary distribution is achieved, the generated samples will be correlated and the effects of autocorrelation need to be taken into account when performing Monte Carlo integration; in fact, the variance of the Monte Carlo estimator~\eqref{eq:MC-integration} will be increased by the presence of autocorrelation as compared to i.i.d. data.
Let $X = (X(t))_{t\in \bb N}$ be a Markov chain with stationary distribution $\bb P_X$, let $f$ be square integrable with respect to $\bb P_X$ and assume that the chain is initialized in the stationary state, i.e. $X(0) \sim \bb P_X$.
Then, the correlation at lag $k$ is defined as
\[
    \rho_k = \frac{\text{Cov}[f(X(0)), f(X(k))]}{\text{Var}[f(X(0))]},
\]
and the chain's autocorrelation time as
\[
    \tau_f = 1 + 2 \sum_{k=1}^{\infty} \rho_k.
\]
Under the hypothesis that the finite-dimensional version of the Central Limit Theorem proved by~\cite{KipnisVaradhan1986} guarantees that 
\[
    \sqrt{\frac{\tau_f}{N}} \left(  \bb E_\pi [f(X(0))] - \frac{1}{N} \sum_{j=1}^{N} f(X(j)) \right) \xrightarrow{d} \mc N(0, \text{Var}[X(0)]).
\]
In particular this implies that, for a finite realization $\{ \theta_j\}_{j=1}^N$ of the$X$, the variance of the mean estimator $\frac{1}{N} \sum_{j=1}^{N} f(\theta_j)$ is not given by $\frac{1}{N} \text{Var}[f(X_1)]$ as in the i.i.d. case, but by $\frac{\tau_f}{N} \text{Var}[f(X(0))]$.
This motivates the introduction of the effective sample size (ESS) of the estimator of $f$ for the samples $\{\theta_j\}_{j=1}^N$ of the chain $X$
\begin{equation}
    \text{ESS}_{\{\theta_j\}}^f = \frac{N}{\tau_X} = \frac{N}{1 + 2 \sum_{k=1}^{\infty} \rho_k} \leq N
\end{equation}
where equality holds if and only if the samples are uncorrelated.
The ESS can be understood as the number of independent samples that would provide an estimator for $\bb E[f(X_1)]$ with the same variance as the correlated samples $\{\theta_j\}_{j=1}^N$, and can be used to assess the quality of the samples generated by the chain.
The larger the autocorrelation time $\tau_f$ the smaller the ESS, requiring more samples achieve a desired certainty level.
In practice, the ESS can be estimated via a batch estimate of the autocorrelation of the samples $\{f(\theta_j)\}_{j=1}^N$ with a truncation the sum at a certain lag $k$; this is often used in practice to estimate the ESS~\cite{Geyer1992}.
If the autocorrelation time is significant, Monte Carlo integration can be rendered more computationally efficient by thinning the chain and keeping only every $h$-th sample, i.e. to consider the samples $\{\theta_{h \cdot l}\}_{l=1}^{N/k}$ instead of $\{\theta_j\}_{j=1}^N$.\medskip

Among MCMC techniques, we mention Ensemble Sampling, whose implementation we will use in the numerical experiments of Section~\ref{sec:exp}.
Ensemble Sampling is introduced by~\cite{GoodmanWeare} as an MCMC technique which guarantees invariance with respect to affine transformation of the parameter space and later generalized.
Ensemble Sampling utilizes an ensemble 
\[
X =(X^1(t), \dots , X^M(t))
\] 
comprising of multiple correlated chains $X^i(t)$ known as walkers.
At step $j$ the walkers are updated sequentially; each walker $X^i$ is updated by drawing a proposal $x^i_P(j+1)$ from a distribution, in this context known as move, which depends on the current state of the ensemble 
\[
  X^i_P(j+1) \sim \mc K\left( \cdot ; x^1(j+1), \dots, x^{i-1}(j+1), x^i(j), x^{i+1}(j), \dots, x^M(j)\right).
\] as in MH, the proposal is then accepted or rejected according to the MH threshold $\alpha$. \newline
The two moves proposed by~\cite{GoodmanWeare} are known as stretch move and walk move.
The first draws a proposal for $X^i$ from the line connecting $x^i(j)$ and the current position $x^k(h_k)$ of another walker $X^k$, for $k \neq i$ randomly selected with $h_k = j$ if $k > i$ and $h_k = j+1$ if $k < i$; a univariate random variable $\Lambda$ of an assigned distribution $\bb P_\Lambda$ is used to select the distance from $x^i(j)$ to $x^k(h_k)$ resulting in the proposal
\begin{equation}\label{eq:stretch-move}
    X^i_P(j+1) \sim x^i(j) + \Lambda \cdot (x^k(h_k) - x^i(j)).
\end{equation}
The second selects a proposal for the walker $X^i$ by drawing sample from a Gaussian distribution centered at $x^i(j)$ and with covariance matrix given by the empirical covariance of a subset of the rest of the walkers,
\begin{equation}\label{eq:walk-move}
    X^i_P(j+1) \sim \mc N\left( x^i(j), \frac{1}{|S|-1} \sum_{k \in S} (x^k(j) - \bar x^S(j))(x^k(j) - \bar x^S(j))^T \right),
\end{equation}
where $S \subseteq \{1, \dots, M\} \setminus \{i\}$ is a subset of the walkers and \[\bar x^S(j) = \frac{1}{|S|}\sum_{k \in S} x^k(j)\] is the mean of the walkers in $S$ at step $j$.
Moves can be combined, randomly picking one or another for each walker at each step, and can be parametrized and tuned to improve the acceptance rate of the proposals.

As the posterior distribution could potentially exhibit multimodal behavior, besides the two moves above we will also adopt the Differential-Independence Mixture Ensemble (DIME) move introduced by~\cite{Boehl}, which combines Ensemble Sampling with ideas from the Differential Evolution MCMC framework introduced by~\cite{TerBraak} and behaves efficiently on multimodal distributions. 
The DIME move divides the ensemble in two subsets of similar size and updates one using a local proposal, the Differential Evolution proposal from~\cite{TerBraak}, and the other using a global proposal with heavy tails, a parametrized multivariate t-distribution.
Thanks to its adaptivity, the DIME move is able to explore the parameter space and to sample efficiently from multimodal distributions without sacrificing the effectiveness on unimodal distributions.

\subsection{Partial differential equation models} \label{sec:PDE}

For this section and the following, we will use Peter Deuflhard and Martin Weiser's Adaptive Numerical Solution of PDEs~\cite{DeuflhardWeiser2012} as a reference; other sources will be quoted when utilized.

Partial differential equations (PDEs) are a class of equations that relate a function of several variables to its partial derivatives.
For a sufficiently smooth function $u : D \rightarrow \R^o$ defined on an open domain $D \subseteq \R^l$, a differential equation of degree $k$ can be first represented as an equation of the form
\[
    F\big(,u(x), \nabla u(x), \nabla^2 u(x), \dots, \nabla^k u(x)\big) = 0,
\]
for a function $F: D \times \R^o \times \R^{o \times l} \times \dots \times \R^{o \times l^k} \rightarrow \R^e$.
If $l =1$, then all the derivatives are univariate and the equation is ordinary differential equation (ODE), while if $l > 1$ the equation is a proper PDE.

A first distinction that can be introduced is that between time-dependent and non time-dependent PDEs.
In fact, despite the fact that the definition of a PDE does not make a distinction between time and space variables, it is often useful for use cases to distinguish between the two.
For the rest of this chapter and the following, $D$ will indicate a generic domain, $\mc X$ will indicate the space-domain of dimension $l$, while $\mc T$ will indicate the time-domain and $t$ will denote a time variable; for time-dependent PDEs the domain will thus be $\mc T \times \mc X$ and the functions $u(t,x)$, while for non time-dependent PDEs the domain will be $\mc X$ and the functions $u(x)$.
A second distinction is that between linear and non-linear PDEs: a PDE is linear if the function $F$ is affine with respect to the unknown function $u$ and its derivatives.
We will only deal with linear PDEs: non linear PDEs are usually more difficult to treat  than linear PDEs, and in many cases they can be approximated by linear PDEs.

Like in ODEs, the solution of a PDE is in usually non unique unless additional information is provided; this information is usually provided in the form of boundary conditions on $\mc X$, which lead to a boundary value problem, in the form of initial conditions on $\mc T$, which lead to an initial value problem, or combining the two.
Unlike ODEs, where the existence and uniqueness of the solution depends on the regularity of the function $f$ around the initial condition, in PDEs the existence of a solution can be more complicated and issues of compatibility between the boundary conditions and the equation can arise.
Moreover, for a PDE different kinds of boundary conditions can be imposed, and we consider three main types of boundary conditions: Dirichlet, Neumann and Robin boundary conditions.
For a subset $B \subseteq \bar D$ of the domain, Dirichlet boundary conditions impose the value of the solution on $B$, i.e.
\[
    u(x) = g(x), \quad \forall x \in B,
\]
for some function $g: B \rightarrow \R^o$;
Neumann boundary conditions impose the value of the normal derivative of the solution on $B$, i.e.
\[
    \partial_{\hat{n}} u(x)= \hat n \nabla u(x) = g(x), \quad \forall x \in B,
\]
where $\hat n$ is the unit normal vector on the boundary $B$; 
finally, Robin boundary conditions impose a linear combination of the value of the solution and its normal derivative on $B$, i.e.
\[
    \partial_{\hat{n}} u(x) + \alpha(x) u(x) = g(x), \quad \forall x \in B.
\]
We will now proceed to introduce some exemplary linear PDEs, which will then be used in the numerical experiments of Section~\ref{sec:exp}.\medskip

The first one is the Poisson equation, given for a scalar function $u$ by 
\begin{equation}\label{eq:Poisson}
    -\Delta u(x) = f(x), 
\end{equation}
over a domain $\mc X \subseteq \R^l$, where $\Delta$ is the Laplace operator, defined as the divergence of the gradient of $u$, 
\[
    \Delta u(x) = \nabla \cdot \nabla u(x) = \sum_{i=1}^{l} \partial^2_{x_i} u(x), 
\] and $f$ is a given scalar function on $\mc X$.
The Poisson equation is a second-order linear PDE and is the simplest representative of elliptic PDEs and is used to model a variety of phenomena, such as heat conduction, electrostatics and fluid flow; its homogeneous version, i.e. with $f=0$, is known as Laplace equation and the solutions of the Laplace equation are known as harmonic functions.

A general solution for the Poisson equation can be derived by the method of Green's functions, which consists in representing the solution as the sum of the convolution of the right-hand side $f$ with a Green's function $G(x,y)$ plus a boundary term~\cite[Chapter 2.2, Theorem 12]{Evans2010}.
Obtaining Green's function is usually a non-trivial task, as it depends on the domain $\mc X$ and the boundary conditions imposed on it.
A crucial element to obtain the Green's function is the fundamental solution of the Laplace equation, which for the 3-dimensional case $l=3$ is given by
\begin{equation}\label{eq:Poisson-fundamental-solution}
    \begin{gathered}
        \Phi : \R^3 \setminus \{0\} \rightarrow \R, \\
        \Phi(x) =  -\frac{1}{4\pi \|x \|_2}.
    \end{gathered}
\end{equation}
The fundamental solution $\Phi$ is harmonic on $\R^l\setminus \{0\}$ and can be derived as a rotationally invariant solution of the Laplace equation.
The key property of the fundamental solution is that the equation 
\[ 
    \Delta \int_{\R^l} \Phi(x-y) f(y) \ dy = f(x) 
\]
holds for every $x \in \R^l$ and $f \in \mc C^2_c(\R^l)$ twice continuously differentiable with compact support~\cite[Theorem 1]{Evans2010}.
This justifies writing \[
    \Delta \Phi(x) = \delta(x),
\]
i.e. the Laplace operator of the fundamental solution is equal to Dirac's delta distribution $\delta$.
Green's function is then defined by 
\[
    G(x,y) = \Phi(y-x) + h_x(y),
\]
where $h_x(y)$ is an harmonic corrector term which guarantees the satisfaction of the boundary conditions imposed on the domain $\mc X$. \medskip

The second type of PDE we will consider is the diffusion or heat equation, given for a scalar function $u$ by
\begin{equation}\label{eq:diffusion}
    \partial_t u - k \Delta u = f,
\end{equation}
on some domain $\mc T \times \mc X$, with $k\in \R^+$ a positive constant and $f$ a given function on $\mc T \times \mc X$ and the Laplacian $\Delta$ acting on the spatial variable $x$.
The diffusion equation is a time-dependent second-order linear PDE and is used to model the diffusion of a quantity $u$ in time and space, such as heat or the concentration of a substance.
$f$ is known as the source term and can be used to model the presence of a source or sink of the diffusing quantity $u$, while $k$ is known as the diffusion coefficient and describes the rate at which the quantity diffuses in space; it is usually assumed to be positive as negative values can be understood as an inversion of the time direction.

Similarly to the Poisson equation, the diffusion equation admits a fundamental solution given by
\[
    \begin{gathered}
        \Phi : \R^l \times \R \rightarrow \R, \\
        \Phi(x,t) = 
        \begin{cases}
            \frac{1}{(4\pi k t)^{l/2}} e^{-\frac{\|x\|_2^2}{4kt}} & \text{for } t > 0 \\
            0 & \text{for } t \leq 0.
        \end{cases}
    \end{gathered}
\]
The fundamental solution of the heat equation can be considered the solution of the initial value problem 
\[
    \begin{cases}
        \partial_t u - k \Delta u = 0 & \\
        u(0,x) = \delta(x). &
    \end{cases}
\]
over $\R^+ \times \R^l$ and has the property that solutions of various problems involving the heat equation can be solved by convolution of a term with the fundamental solution~\cite[Chapter 2.3, Theorem 1-2]{Evans2010}.\medskip

Finally, the third equations we will consider are the Lamè-Navier or stationary Navier-Cauchy equations, which describe the deformation of an elastic body under the action of external forces at the equilibrium.
These equations are a system of second-order linear elliptic PDEs and involve the displacement field $u: \mc X \rightarrow \R^o$, with tipically $o=2$ or $o=3$; they are given by 
\begin{equation}\label{eq:Navier-Lame}
    -2\mu \Delta u - \lambda \nabla (\nabla \cdot u) = f,
\end{equation}
where the Laplacian $\Delta$ acts componentwise on the vector $u$ and $\lambda, \mu$ are the Lamè parameters, which are related to the material properties of the body.
$f$ is a given vector function on $\mc X$ and represents the external forces acting on the body.
To derive the equations, we consider the following set of equations on $\mc X$:
\begin{numcases}{}
        - \nabla \cdot T = f, \label{eq:continuity} \\
        \epsilon = \frac{1}{2} \left( \nabla u + (\nabla u)^T \right), \label{eq:linearized-strain} \\
        T = \lambda \text{Trace}(\epsilon) I_o + 2\mu \epsilon \label{eq:constitutive-law}
\end{numcases}
where $T$ is the stress tensor, $I_o$ is the identity tensor and $\epsilon$ is the strain tensor; for simplicity we identified 2-tensors on $\R^o$ with matrices in $R^{o\times o}$. \newline
The first equation~\eqref{eq:continuity} is the continuity equation, relating the divergence of the stress tensor $T$ to the external forces $f$ acting on the body; the stress tensor can be understood as expressing at an infinitesimal level the internal forces of the body, so the first equation imposes an equilibrium between forces.
The second equation~\eqref{eq:linearized-strain} relates the displacement field $u$ to the strain tensor $\epsilon$, which represents the infinitesimal deformation of the body in a point.
The strain tensor $\epsilon$ defined by~\eqref{eq:linearized-strain} is known as the linearized strain tensor, as it can be derived as the linearization in $\nabla u$ of a general and non-linear strain tensor, known as the Green-Lagrange strain tensor~\cite[Section 2.3]{DeuflhardWeiser2012}; this linearization is a reasonable assumption for small deformations and allows us to obtain a linear PDE. 
Finally, the third equation~\eqref{eq:constitutive-law} is known as the material's constituitive equation and relates the stress tensor $T$ to the strain tensor $\epsilon$ through the Lamè parameters $\lambda$ and $\mu$; this relation corresponds to isotropic linear elastic behavior from the body, which is a reasonable assumption for small strains and allows to derive Hooke's Law. \newline
The parameters $\lambda$ and $\mu$ in the constituitive equation are particularly interesting as they depend on the specific material of the body and in real-world cases often need to be identified: Experiment~\ref{sec:FEexp} will deal with such problem.
As common in practice instead of the Lamè parameters we will identify two equivalent parameters, the Young's modulus $E$ and the Poisson's ratio $\nu$, which are related to the Lamè parameters by the relations
\begin{equation}\label{eq:material-parameters}
    \begin{gathered}
        E = \frac{\mu(3\lambda + 2\mu)}{\lambda + \mu}, \\
        \nu = \frac{\lambda}{2(\lambda + \mu)}.
    \end{gathered}
\end{equation}
$E$ and $\nu$ are the most commonly employed parameters due to their physical interpretation: in fact, let us consider the 3-dimensional $o=3$ case and let $e_1,e_2,e_3$ be the canonical basis of $\R^3$.
For an axial stress $T = \sigma e_1 \otimes e_1$, by inverting the constituitive equation~\eqref{eq:constitutive-law} and inserting equations~\eqref{eq:material-parameters} one finds 
\[
    \epsilon = \frac{1}{E} \sigma e_1 \otimes e_1 + \frac{\nu}{E} \sigma ( e_2 \otimes e_2 + e_3 \otimes e_3).
\]  
Consequently, Young's modulus $E$ can be interpreted as the ratio between the stress and the strain in the direction of the stress, while Poisson's ratio $\nu$ can be interpreted as the ratio between the strain in the direction of the stress and the strain in the orthogonal directions.



\subsection{Adaptive Finite Element method} \label{sec:AdaFE}